{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7382d298-bd37-4705-8984-b4737f36ec0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import time\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3ac0c56-cb05-4264-975a-dce3ead20f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "args:\n",
    "PERCEVAL_LOCATION - gets the location of perceval in our local system\n",
    "FILE_SAVE_LOCATION - the location to save the queried data in the form of a .json file per repository\n",
    "repository - the owner_name/repositoriy_name of the corresponding GitHub repository that we want to query\n",
    "GiHuB_API_KEY - the GitHub API key for querying the data (limit is 5000 queries per hour)\n",
    "\n",
    "This function uses perceval tool to query our required data (issue, pul_request) for the required repository. Converts the returned output in string format to\n",
    ".json format and saves the .json file in the name of owner_name/repository_name.json at the given location to save.\n",
    "\n",
    "\n",
    "'''\n",
    "def query_and_save_data_using_perceval(PERCEVAL_LOCATION, FILE_SAVE_LOCATION, repository, GiHuB_API_KEY):\n",
    "    \n",
    "    owner_name = repository.split(r'/')[0]\n",
    "    repo_name = repository.split(r'/')[1]\n",
    "    COMMAND_STRING = PERCEVAL_LOCATION + ' && perceval github {0} {1} --from-date 2021-12-01 --json-line --sleep-for-rate -t {2} '.format(owner_name, repo_name, GiHuB_API_KEY)\n",
    "    command_output = os.popen(COMMAND_STRING)\n",
    "    command_result = command_output.read()\n",
    "    \n",
    "    file_save_name = FILE_SAVE_LOCATION + '{0}_{1}.json'.format(owner_name, repo_name)\n",
    "    dict_list = [d.strip() for d in command_result.splitlines()]\n",
    "    j = [json.loads(i) for i in dict_list]\n",
    "    with open(file_save_name, 'w') as outfile:\n",
    "        json.dump(j, outfile, indent = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7217fdd-1a6a-4059-bb0b-6089a8bf9a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "PERCEVAL_LOCATION = 'source ./../../venv/bin/activate' # perceval tool location\n",
    "FILE_SAVE_LOCATION = r'./../Data/' # folder to save the query result\n",
    "GiHuB_API_KEY = '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'\n",
    "repository_list = ['diem/diem', 'paritytech/substrate', 'rust-lang/rust', 'servo/servo'] #repositories that needs to be queried"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11115a2d-d0c2-43a3-9f4d-38e080740f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query the tool for each repository individually\n",
    "for repository in tqdm(repository_list):\n",
    "    query_using_perceval(PERCEVAL_LOCATION, FILE_SAVE_LOCATION, repository, GiHuB_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cfeb54-6f9a-4a3a-80fd-52ae9f0c4b91",
   "metadata": {},
   "source": [
    "## read_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6736e63f-2f2f-4f9e-9de0-870f0e3fce3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['paritytech_substrate.json',\n",
       " 'servo_servo.json',\n",
       " 'diem_diem.json',\n",
       " 'rust-lang_rust.json']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files = os.listdir('./../Data/')\n",
    "files.remove(\".ipynb_checkpoints\")\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3c2d7fe7-1d7a-4447-90f7-f53f0cd5d9d2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paritytech_substrate.json\n",
      "--------------------------------------------------\n",
      "servo_servo.json\n",
      "--------------------------------------------------\n",
      "diem_diem.json\n",
      "--------------------------------------------------\n",
      "rust-lang_rust.json\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "for file_name in files: \n",
    "    print(file_name)\n",
    "    # Opening JSON file\n",
    "    f = open('./../Data/'+file_name)\n",
    "\n",
    "    # returns JSON object as\n",
    "    # a dictionary\n",
    "    file = json.load(f)\n",
    "    data_frame = pd.DataFrame(columns=['author', 'body', 'number', 'created_at', 'empty']) \n",
    "    # Iterating through the json\n",
    "    # list\n",
    "    for i in file:\n",
    "        try:\n",
    "            # print(i['data'])\n",
    "            # print(i['data']['number'])\n",
    "            for j in range(len(i['data']['comments_data'])):\n",
    "                empty = 0\n",
    "                if len(i['data']['comments_data'][j]['body']) < 2:\n",
    "                    empty = 1\n",
    "                data_frame = data_frame.append({'author': i['data']['comments_data'][j]['user_data']['login'],\n",
    "                                   'body': i['data']['comments_data'][j]['body'],\n",
    "                                   'number': i['data']['number'],\n",
    "                                   'created_at': i['data']['comments_data'][j]['created_at'],\n",
    "                                   'empty': empty\n",
    "                                  }, ignore_index=True)\n",
    "                # print(i['data']['comments_data'][j]['body'])\n",
    "                # print(i['data']['comments_data'][j]['user_data']['login'])\n",
    "                # print(i['data']['comments_data'][j]['created_at'])\n",
    "                # print('#'*50)\n",
    "        except:\n",
    "            print('empty')\n",
    "\n",
    "        # break\n",
    "    f.close()\n",
    "    data_frame.to_csv('./../Data_frames/'+file_name.split(\".\")[0]+'.csv')\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27245ca-8e8d-49bb-96b3-f4d489f9f1a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
